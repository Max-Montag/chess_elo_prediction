method: grid
metric:
  goal: minimize
  name: val_loss
parameters:
  learning_rate:
    values: [0.00000008, 0.00000009, 0.0000001, 0.00000011, 0.00000012]
  weight_decay:
    values: [0.00015, 0.0002, 0.00025, 0.0003, 0.00035, 0.0004]
    conditional:
      n_layers:
        1: [0.00015, 0.0002, 0.00025, 0.0003, 0.00035, 0.0004]
        2: [0.00015, 0.0002, 0.00025, 0.0003, 0.00035, 0.0004]
        3: [0.0002, 0.00025, 0.0003, 0.00035, 0.0004]
        4: [0.00025, 0.0003, 0.00035, 0.0004]
  mask_prob:
    values: [0.3, 0.35, 0.4, 0.45]
  batch_size:
    values: [32, 64]
  dropout:
    values: [0.3, 0.35, 0.4, 0.45, 0.47, 0.5, 0.52]
    conditional:
      n_layers:
        1: [0.3, 0.35, 0.4, 0.45, 0.47, 0.5, 0.52]
        2: [0.3, 0.35, 0.4, 0.45, 0.47, 0.5, 0.52]
        3: [0.4, 0.45, 0.47, 0.5, 0.52]
        4: [0.45, 0.47, 0.5, 0.52]
  reload_interval:
    values: [1, 2, 3, 4, 5, 7, 10, 15]
  n_layers:
    values: [1, 2, 3, 4]
  embed_dim:
    values: [16, 32, 64, 128]
    conditional:
      n_layers:
        1: [32, 64, 128]
        2: [32, 64, 128]
        3: [32, 64]
        4: [16, 32]
  use_weighted_loss:
    values: [true, false]
  seed:
    values: [18]
  dataset_size:
    values: [10000]
  num_epochs:
    values: [50]
  vocab_size:
    values: [11117]
  mask_token:
    values: [11116]
  nhead:
    values: [4]
  activation:
    values: ["relu", "gelu", "leaky_relu", "tanh", "sigmoid"]
